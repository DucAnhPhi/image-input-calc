{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 2109/60000 [00:00<00:02, 21081.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing MNIST training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:03<00:00, 18755.49it/s]\n",
      "  6%|▌         | 551/10000 [00:00<00:01, 5509.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing MNIST training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 14665.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create MNIST data arrays\n",
    "%run ./generate_mnist_dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 151241/151241 [00:00<00:00, 765493.56it/s]\n",
      "100%|██████████| 60000/60000 [00:05<00:00, 10847.07it/s]\n",
      "100%|██████████| 60000/60000 [00:00<00:00, 340915.79it/s]\n",
      "100%|██████████| 16992/16992 [00:00<00:00, 634669.83it/s]\n",
      "  8%|▊         | 791/10000 [00:00<00:01, 7905.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No training data for ). Skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 9472.31it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 294614.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No training data for ). Skipping\n",
      "No training data for 0. Skipping\n",
      "No training data for 1. Skipping\n",
      "No training data for 2. Skipping\n",
      "No training data for 3. Skipping\n",
      "No training data for 4. Skipping\n",
      "No training data for 5. Skipping\n",
      "No training data for 6. Skipping\n",
      "No training data for 7. Skipping\n",
      "No training data for 8. Skipping\n",
      "No training data for 9. Skipping\n",
      "No training data for brckts. Skipping\n",
      "No training data for ). Skipping\n",
      "No training data for 0. Skipping\n",
      "No training data for 1. Skipping\n",
      "No training data for 2. Skipping\n",
      "No training data for 3. Skipping\n",
      "No training data for 4. Skipping\n",
      "No training data for 5. Skipping\n",
      "No training data for 6. Skipping\n",
      "No training data for 7. Skipping\n",
      "No training data for 8. Skipping\n",
      "No training data for 9. Skipping\n",
      "No training data for brckts. Skipping\n",
      "No training data for ). Skipping\n",
      "No training data for 0. Skipping\n",
      "No training data for 1. Skipping\n",
      "No training data for 2. Skipping\n",
      "No training data for 3. Skipping\n",
      "No training data for 4. Skipping\n",
      "No training data for 5. Skipping\n",
      "No training data for 6. Skipping\n",
      "No training data for 7. Skipping\n",
      "No training data for 8. Skipping\n",
      "No training data for 9. Skipping\n",
      "No training data for -. Skipping\n",
      "No training data for div. Skipping\n",
      "No training data for ). Skipping\n",
      "No training data for 0. Skipping\n",
      "No training data for 1. Skipping\n",
      "No training data for 2. Skipping\n",
      "No training data for 3. Skipping\n",
      "No training data for 4. Skipping\n",
      "No training data for 5. Skipping\n",
      "No training data for 6. Skipping\n",
      "No training data for 7. Skipping\n",
      "No training data for 8. Skipping\n",
      "No training data for 9. Skipping\n",
      "No training data for -. Skipping\n",
      "No training data for div. Skipping\n",
      "No training data for ). Skipping\n",
      "Train data length: 68133\n",
      "Test data length: 12817\n",
      "Img Shape: torch.Size([1, 32, 32])\n",
      "Number of Labels: 15\n",
      "Train data length: 3831\n",
      "Test data length: 1155\n",
      "Img Shape: torch.Size([1, 32, 32])\n",
      "Number of Labels: 15\n",
      "Train data length: 3894\n",
      "Test data length: 1330\n",
      "Img Shape: torch.Size([1, 32, 32])\n",
      "Number of Labels: 15\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare the data\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from training_data import DataCollection\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def print_data_infos(data_train, data_test):\n",
    "    print(\"Train data length: {0}\".format(len(data_train.data)))\n",
    "    print(\"Test data length: {0}\".format(len(data_test.data)))\n",
    "    print(\"Img Shape: {0}\".format(data_train.data[0].shape))\n",
    "    print(\"Number of Labels: {0}\".format(data_train.no_labels))\n",
    "    \n",
    "data_all_train = DataCollection()\n",
    "data_all_test = DataCollection(train=False)\n",
    "\n",
    "data_ops_train = DataCollection(use_hasy=False, use_mnist=False, own_path='plus-min-div')\n",
    "data_ops_test = DataCollection(use_hasy=False, use_mnist=False, own_path='plus-min-div', train=False)\n",
    "\n",
    "data_brckts_train = DataCollection(use_hasy=False, use_mnist=False, own_path='plus-brckts')\n",
    "data_brckts_test = DataCollection(use_hasy=False, use_mnist=False, own_path='plus-brckts', train=False)\n",
    "\n",
    "print_data_infos(data_all_train, data_all_test)\n",
    "print_data_infos(data_ops_train, data_ops_test)\n",
    "print_data_infos(data_brckts_train, data_brckts_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the network and some utilities\n",
    "\n",
    "from torchvision import models\n",
    "from torch.nn import Conv2d\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train(train_loader, test_loader, model_name, print_step, epochs=5):\n",
    "    model = models.alexnet(num_classes=15)\n",
    "    model.features[0] = Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    if torch.cuda.is_available():\n",
    "        model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.8, 0.99), weight_decay=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch {0}\".format(epoch))\n",
    "        for step, [x_train, y_train] in enumerate(tqdm(train_loader)):\n",
    "            if torch.cuda.is_available():\n",
    "                 x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            train_pred = model(x_train)\n",
    "            loss = criterion(train_pred, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if step % print_step == 0:\n",
    "                print('Loss: {}'.format(loss))\n",
    "        \n",
    "        acc = calc_accuracy(model, test_loader)\n",
    "        print(\"Accuracy: {0}\".format(acc))\n",
    "        if acc > 98:\n",
    "            torch.save(model.state_dict(), '{0}-{1}.ckpt'.format(model_name,acc))\n",
    "    print(\"Accuracy: {0}\".format(acc))\n",
    "    torch.save(model.state_dict(), '{0}.ckpt'.format(model_name))\n",
    "\n",
    "def calc_accuracy(model, test_loader):\n",
    "    accuracies = []\n",
    "    for idx, [x_test, y_test] in enumerate(tqdm(test_loader)):\n",
    "        if torch.cuda.is_available():\n",
    "            x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "        test_pred = model(x_test)\n",
    "        accuracy = 100 * torch.mean((torch.argmax(test_pred, dim=1) == y_test).float())\n",
    "        accuracies.append(accuracy.item() if torch.cuda.is_available() else accuracy)\n",
    "    return np.mean(accuracies)  \n",
    "\n",
    "train_all_loader = DataLoader(data_all_train, batch_size=16, shuffle=True)\n",
    "test_all_loader = DataLoader(data_all_test, batch_size=16, shuffle=False)\n",
    "\n",
    "train_ops_loader = DataLoader(data_ops_train, batch_size=16, shuffle=True)\n",
    "test_ops_loader = DataLoader(data_ops_test, batch_size=16, shuffle=False)\n",
    "\n",
    "train_brckts_loader = DataLoader(data_brckts_train, batch_size=16, shuffle=True)\n",
    "test_brckts_loader = DataLoader(data_brckts_test, batch_size=16, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4259 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/4259 [00:00<32:25,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.708343505859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 501/4259 [05:14<34:45,  1.80it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2580705881118774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 658/4259 [07:13<1:20:36,  1.34s/it]"
     ]
    }
   ],
   "source": [
    "train(train_all_loader, test_all_loader, 'model-all-symbols', 500)\n",
    "train(train_ops_loader, test_ops_loader, 'model-plus-minus-div', 60)\n",
    "train(train_brckts_loader, test_brckts_loader, 'model-plus-brackets', 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = calc_accuracy(torch_model)\n",
    "print(\"Accuracy: {0}\".format(acc))\n",
    "torch.save(torch_model.state_dict(), 'combined-model-v3.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
