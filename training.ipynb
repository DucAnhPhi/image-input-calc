{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "train_data = MNIST('mnist_train', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_data = MNIST('mnist_test', train=False, transform=transforms.ToTensor(), download=True)\n",
    "print(\"Train data shape: {0}\".format(train_data.data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from network import CharacterClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_dim = (1, 28, 28)\n",
    "hidden_layers = [50, 100, 500]\n",
    "output_dim = 10\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=16, shuffle=False)\n",
    "\n",
    "model = CharacterClassifier(input_dim, hidden_layers, output_dim)\n",
    "model.train()\n",
    "\n",
    "epochs = 5\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "        print(\"Epoch {0}\".format(epoch))\n",
    "        for step, [x_train, y_train] in enumerate(tqdm(train_loader)):\n",
    "            optimizer.zero_grad()\n",
    "            train_pred = model(x_train)\n",
    "            loss = criterion(train_pred, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if step % 300 == 0:\n",
    "                print('Loss: {}'.format(loss))\n",
    "            torch.save(model.state_dict(), 'cc{}.ckpt'.format(step))                \n",
    "model.eval()\n",
    "accuracies = []\n",
    "for idx, [x_test, y_test] in enumerate(tqdm(test_loader, desc='Test')):\n",
    "    test_pred = model(x_test)\n",
    "    accuracy = 100 * torch.mean((torch.argmax(test_pred, dim=1) == y_test).float())\n",
    "    accuracies.append(accuracy)\n",
    "print(\"Accuracy: {0}\".format(np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "file_path = \"SubImages\"\n",
    "raw_images = []\n",
    "images = []\n",
    "for file_name in os.listdir(file_path):\n",
    "    img = cv2.imread(file_path+'/'+file_name)\n",
    "    img = cv2.resize(img, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    raw_images.append(img)\n",
    "    np_img = np.asarray(img).reshape((1, 28, 28))\n",
    "    images.append(np_img)  \n",
    "image_tensor = torch.Tensor(images)\n",
    "prediction = model(image_tensor)\n",
    "labels = torch.argmax(prediction, dim=1)\n",
    "\n",
    "eps = 1e-08\n",
    "\n",
    "i = 0\n",
    "for label in labels: \n",
    "    plt.imshow(raw_images[i])\n",
    "    plt.show()  \n",
    "    print(label)  \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "151241it [01:09, 2189.50it/s]\n",
      "16992it [00:08, 2098.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: torch.Size([151241, 3, 64, 64])\n",
      "Test data shape: torch.Size([16992, 3, 64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from network import CharacterClassifier\n",
    "from tqdm import tqdm\n",
    "from training_data import HASY\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "hasy_train = HASY('HASY')\n",
    "hasy_test = HASY('HASY', train=False)\n",
    "\n",
    "print(\"Train data shape: {0}\".format(hasy_train.data.shape))\n",
    "print(\"Test data shape: {0}\".format(hasy_test.data.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2.1834, 2.1834, 2.1834,  ..., 2.1834, 2.1834, 2.1834],\n",
      "         [2.1834, 2.1834, 2.1834,  ..., 2.1834, 2.1834, 2.1834],\n",
      "         [2.1834, 2.1834, 2.1834,  ..., 2.1834, 2.1834, 2.1834],\n",
      "         ...,\n",
      "         [2.1834, 2.1834, 2.1834,  ..., 2.1834, 2.1834, 2.1834],\n",
      "         [2.1834, 2.1834, 2.1834,  ..., 2.1834, 2.1834, 2.1834],\n",
      "         [2.1834, 2.1834, 2.1834,  ..., 2.1834, 2.1834, 2.1834]],\n",
      "\n",
      "        [[2.1834, 2.1834, 2.1834,  ..., 2.1834, 2.1834, 2.1834],\n",
      "         [2.1834, 2.1834, 2.1834,  ..., 2.1834, 2.1834, 2.1834],\n",
      "         [2.1834, 2.1834, 2.1834,  ..., 2.1834, 2.1834, 2.1834],\n",
      "         ...,\n",
      "         [2.1834, 2.1834, 2.1834,  ..., 2.1834, 2.1834, 2.1834],\n",
      "         [2.1834, 2.1834, 2.1834,  ..., 2.1834, 2.1834, 2.1834],\n",
      "         [2.1834, 2.1834, 2.1834,  ..., 2.1834, 2.1834, 2.1834]],\n",
      "\n",
      "        [[2.1834, 2.1834, 2.1834,  ..., 2.1834, 2.1834, 2.1834],\n",
      "         [2.1834, 2.1834, 2.1834,  ..., 2.1834, 2.1834, 2.1834],\n",
      "         [2.1834, 2.1834, 2.1834,  ..., 2.1834, 2.1834, 2.1834],\n",
      "         ...,\n",
      "         [2.1834, 2.1834, 2.1834,  ..., 2.1834, 2.1834, 2.1834],\n",
      "         [2.1834, 2.1834, 2.1834,  ..., 2.1834, 2.1834, 2.1834],\n",
      "         [2.1834, 2.1834, 2.1834,  ..., 2.1834, 2.1834, 2.1834]]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "test_img = transforms.ToPILImage()(hasy_train.data[0])\n",
    "plt.imshow(test_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9453 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test:   0%|          | 0/1062 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 5.915121078491211\n"
     ]
    }
   ],
   "source": [
    "hasy_model = CharacterClassifier((3, 64, 64), [50, 100, 500], hasy_train.no_labels)\n",
    "hasy_model.train()\n",
    "\n",
    "epochs = 5\n",
    "optimizer = torch.optim.SGD(hasy_model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_loader = DataLoader(hasy_train, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(hasy_test, batch_size=16, shuffle=False)\n",
    "    \n",
    "for epoch in range(epochs):\n",
    "        print(\"Epoch {0}\".format(epoch))\n",
    "        for step, [x_train, y_train] in enumerate(tqdm(train_loader)):\n",
    "            optimizer.zero_grad()\n",
    "            train_pred = hasy_model(x_train)\n",
    "            loss = criterion(train_pred, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if step % 600 == 0:\n",
    "                print('Loss: {}'.format(loss))\n",
    "                accuracies = []\n",
    "                for idx, [x_test, y_test] in enumerate(tqdm(test_loader, desc='Test')):\n",
    "                    test_pred = hasy_model(x_test)\n",
    "                    accuracy = 100 * torch.mean((torch.argmax(test_pred, dim=1) == y_test).float())\n",
    "                    accuracies.append(accuracy)\n",
    "                print(\"Accuracy: {0}\".format(np.mean(accuracies)))  \n",
    "torch.save(hasy_model.state_dict(), 'hasy_model.ckpt')        \n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
