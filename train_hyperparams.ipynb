{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 151241/151241 [00:00<00:00, 271214.88it/s]\n",
      "100%|██████████| 60000/60000 [00:11<00:00, 5145.46it/s]\n",
      "100%|██████████| 60000/60000 [00:00<00:00, 168741.98it/s]\n",
      " 40%|███▉      | 6747/16992 [00:00<00:00, 67469.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No training data for 0. Skipping\n",
      "No training data for 1. Skipping\n",
      "No training data for 2. Skipping\n",
      "No training data for 3. Skipping\n",
      "No training data for 4. Skipping\n",
      "No training data for 5. Skipping\n",
      "No training data for 6. Skipping\n",
      "No training data for 7. Skipping\n",
      "No training data for 8. Skipping\n",
      "No training data for 9. Skipping\n",
      "No training data for +. Skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16992/16992 [00:00<00:00, 130284.41it/s]\n",
      "100%|██████████| 10000/10000 [00:02<00:00, 4834.03it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 159338.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No training data for 0. Skipping\n",
      "No training data for 1. Skipping\n",
      "No training data for 2. Skipping\n",
      "No training data for 3. Skipping\n",
      "No training data for 4. Skipping\n",
      "No training data for 5. Skipping\n",
      "No training data for 6. Skipping\n",
      "No training data for 7. Skipping\n",
      "No training data for 8. Skipping\n",
      "No training data for 9. Skipping\n",
      "No training data for +. Skipping\n",
      "Train data length: 60405\n",
      "Test data length: 10045\n",
      "Img Shape: torch.Size([1, 32, 32])\n",
      "Number of Labels: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from network import CharacterClassifier\n",
    "from tqdm import tqdm\n",
    "from training_data import CombinedData\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "hasy_train = CombinedData('HASY')\n",
    "hasy_test = CombinedData('HASY', train=False)\n",
    "\n",
    "print(\"Train data length: {0}\".format(len(hasy_train.data)))\n",
    "print(\"Test data length: {0}\".format(len(hasy_test.data)))\n",
    "print(\"Img Shape: {0}\".format(hasy_train.data[0].shape))\n",
    "print(\"Number of Labels: {0}\".format(hasy_train.no_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 307/3776 [03:55<32:26,  1.78it/s]  "
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from torch.nn import Conv2d\n",
    "\n",
    "train_loader = DataLoader(hasy_train, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(hasy_test, batch_size=16, shuffle=False)\n",
    "\n",
    "def calc_accuracy(model):\n",
    "    accuracies = []\n",
    "    for idx, [x_test, y_test] in enumerate(test_loader):\n",
    "        test_pred = model(x_test)\n",
    "        accuracy = 100 * torch.mean((torch.argmax(test_pred, dim=1) == y_test).float())\n",
    "        accuracies.append(accuracy)\n",
    "    return np.mean(accuracies) \n",
    "\n",
    "def print_stats(lr, beta1, beta2, decay, accuracy):\n",
    "    print(\"Learning rate: {0}\".format(lr))\n",
    "    print(\"Beta 1: {0}\".format(beta1))\n",
    "    print(\"Beta 2: {0}\".format(beta2))\n",
    "    print(\"Weight decay: {0}\".format(decay))\n",
    "    print(\"Accuracy: {0}\".format(accuracy))\n",
    "\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "betas1 = [0.8, 0.85, 0.9, 0.95]\n",
    "betas2 = [0.9, 0.925, 0.95, 0.99]\n",
    "weight_decays = [0, 0.01, 0.001, 0.0001]\n",
    "\n",
    "best_lr = 0\n",
    "best_beta1 = 0\n",
    "best_beta2 = 0\n",
    "best_decay = 0\n",
    "best_accuracy = 0\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for beta1 in betas1:\n",
    "        for beta2 in betas2:\n",
    "            for decay in weight_decays:\n",
    "                model = models.alexnet(num_classes=15)\n",
    "                model.features[0] = Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(beta1, beta2), weight_decay=decay)\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "                for step, [x_train, y_train] in enumerate(tqdm(train_loader)):\n",
    "                    optimizer.zero_grad()\n",
    "                    train_pred = model(x_train)\n",
    "                    loss = criterion(train_pred, y_train)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                accuracy = calc_accuracy(model)\n",
    "                print_stats(lr, beta1, beta2, decay, accuracy)\n",
    "                if accuracy > best_accuracy:\n",
    "                    best_lr = lr\n",
    "                    best_beta1 = beta1\n",
    "                    best_beta2 = beta2\n",
    "                    best_decay = decay\n",
    "                    best_accuracy = accuracy\n",
    "                    \n",
    "print(\"Best hyperparameters:\")\n",
    "print_stats(best_lr, best_beta1, best_beta2, best_decay, best_accuracy)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
